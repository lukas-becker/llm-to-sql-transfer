{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba21eb09-524f-4e02-8493-76caa8f2aad8",
   "metadata": {},
   "source": [
    "# Automatic Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a0f6a57-1938-4d1b-a2ed-2b6495bc7b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging face cache directory from ENV: C:\\Users\\Lukas\\.cache\\huggingface\\hub\\\n",
      "Client from ENV: gpu_3070\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import new_zealand\n",
    "import covid\n",
    "import weather\n",
    "import phi2\n",
    "import pipsql\n",
    "import llama2\n",
    "import sqlcoder\n",
    "import gpt4\n",
    "\n",
    "models = ['pip-sql', 'gpt-4']#['llama-2', 'phi2', 'sqlcoder', 'pip-sql', 'gpt-4']\n",
    "datasets = ['new_zealand', 'covid', 'weather']\n",
    "load_dotenv()\n",
    "hf_cache_directory = os.getenv(\"HF_CACHE_DIRECTORY\")\n",
    "access_token = os.getenv(\"ACCESS_TOKEN\")\n",
    "client = os.getenv(\"CLIENT\")\n",
    "\n",
    "print(\"Hugging face cache directory from ENV: \" + str(hf_cache_directory))\n",
    "print(\"Client from ENV: \" + str(client))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671a87ad-8922-4fdb-9c24-91669b009560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Query generation statistics: ***\n",
      "Client: gpu_3070\n",
      "Model: pipSQL\n",
      "Dataset: new_zealand\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dab5601092a4ef8a261cd27c3204f23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Setting `pad_token_id` to `eos_token_id`:32021 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating response for prompt 1: How many of the usual residents of New Zealand were born in Germany?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:32021 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 217.443655 seconds\n",
      "Model response:\n",
      "SELECT sum(Census_usually_resident_population_count) FROM new_zealand_birthplace_2018_census WHERE Birthplace LIKE '%Germany%'\n",
      "\n",
      "Generating response for prompt 2: In how many different regions where the usual residents of New Zealand born?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:32021 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 232.000717 seconds\n",
      "Model response:\n",
      "SELECT count(DISTINCT Census_usually_resident_population_count) FROM new_zealand_birthplace_2018_census\n",
      "\n",
      "Generating response for prompt 3: How many percent of the usual residents of new zealand where born in New Zealand?\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    for dataset in datasets:\n",
    "        if dataset == 'new_zealand':\n",
    "            ddl = new_zealand.ddl\n",
    "            prompts = new_zealand.prompts\n",
    "    \n",
    "        elif dataset == 'covid': \n",
    "            ddl = covid.ddl\n",
    "            prompts = covid.prompts\n",
    "    \n",
    "        elif dataset == 'weather':\n",
    "            ddl = weather.ddl\n",
    "            prompts = weather.prompts\n",
    "\n",
    "        # let model create all \n",
    "        if model == 'llama-2':\n",
    "            llama2.run(client, ddl, prompts, hf_cache_directory, dataset, access_token)\n",
    "            pass\n",
    "            \n",
    "        elif model == 'phi2':\n",
    "            phi2.run(client, ddl, prompts, hf_cache_directory, dataset)\n",
    "            pass\n",
    "\n",
    "        elif model == 'sqlcoder':\n",
    "            sqlcoder.run(client, ddl, prompts, hf_cache_directory, dataset)\n",
    "            pass\n",
    "\n",
    "        elif model == 'pip-sql':\n",
    "            pipsql.run(client, ddl, prompts, hf_cache_directory, dataset)\n",
    "            pass\n",
    "\n",
    "        elif model == 'gpt-4':\n",
    "            gpt4.run(client, ddl, prompts, dataset)\n",
    "            pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
